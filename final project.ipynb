{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaneeza Kamil\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2723: DtypeWarning: Columns (27,30,34,35,36,41,42,43,44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "#from sklearn.cross_validation import train_test_split \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.polynomial.polynomial as poly\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv(\"qudditch_training_0_1.csv\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101268, 48)\n",
      "(101267, 20)\n",
      "(101268, 1)\n",
      "['Gryffindor' 'Female' 11.0 6.0 25.0 1.0 1.0 '38' 41.0 0.0 1.0 0.0 0.0 0.0\n",
      " 'Beater' 1.0 'None' '0' '0' 0.0]\n",
      "['Gryffindor' 'Female' 11.0 6.0 25.0 1.0 1.0 '38' 41.0 0.0 1.0 0.0 0.0 0.0\n",
      " 'Beater' 1.0 'None' '0' 0 0]\n",
      "[11.0 6.0 25.0 1.0 1.0 '38' 41.0 0.0 1.0 0.0 0.0 0.0 'Beater' 1.0 'None'\n",
      " '0' 0 0 1.0 0.0 0.0 0.0 1.0 0.0]\n",
      "[[1.0 0.0 0.0 0.0]\n",
      " [1.0 0.0 0.0 0.0]\n",
      " [0.0 0.0 0.0 1.0]\n",
      " [1.0 0.0 0.0 0.0]\n",
      " [1.0 0.0 0.0 0.0]\n",
      " [1.0 0.0 0.0 0.0]\n",
      " [1.0 0.0 0.0 0.0]\n",
      " [1.0 0.0 0.0 0.0]\n",
      " [1.0 0.0 0.0 0.0]\n",
      " [1.0 0.0 0.0 0.0]\n",
      " [0.0 0.0 0.0 1.0]\n",
      " [0.0 0.0 0.0 1.0]\n",
      " [1.0 0.0 0.0 0.0]\n",
      " [1.0 0.0 0.0 0.0]\n",
      " [0.0 0.0 0.0 1.0]\n",
      " [0.0 0.0 0.0 1.0]\n",
      " [0.0 0.0 0.0 1.0]\n",
      " [1.0 0.0 0.0 0.0]\n",
      " [0.0 0.0 0.0 1.0]\n",
      " [0.0 0.0 0.0 0.0]]\n",
      "[[1.0 0.0]\n",
      " [1.0 0.0]\n",
      " [1.0 0.0]\n",
      " [0.0 1.0]\n",
      " [0.0 1.0]\n",
      " [0.0 1.0]\n",
      " [0.0 1.0]\n",
      " [0.0 1.0]\n",
      " [1.0 0.0]\n",
      " [1.0 0.0]\n",
      " [1.0 0.0]\n",
      " [0.0 1.0]\n",
      " [1.0 0.0]\n",
      " [0.0 1.0]\n",
      " [1.0 0.0]\n",
      " [0.0 1.0]\n",
      " [0.0 1.0]\n",
      " [1.0 0.0]\n",
      " [0.0 1.0]\n",
      " [0.0 1.0]]\n"
     ]
    }
   ],
   "source": [
    "#data = (df[~np.isnan(df).any(axis=1)])\n",
    "\n",
    "print(df.shape)\n",
    "data = df.values\n",
    "X0 = data[0:101267,2:47]\n",
    "X1 = np.delete(X0,[3,8,18,21,22,23,24,25,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43],1)\n",
    "#X1:house, gender, age, foul_type_id, game_move_id,penalty_id,game_duration,move_speciality,num_game_moves,\n",
    "#   num_game_losses,num_practice_sessions,num_games_satout,num_games_injured,num_games_notpartof,player_type,\n",
    "#   num_games_won,stooging?,body_blow?,power_play?,sloth_grip_roll?,change,snitch_caught\n",
    "\n",
    "Y0 = data[:,-1]\n",
    "print(X1.shape)\n",
    "\n",
    "#Y0 = np.array(Y0)\n",
    "Y = Y0=='YES'\n",
    "Y = Y.reshape((Y.shape[0],1))\n",
    "print(Y.shape)\n",
    "\n",
    "gryffindor = np.zeros((X1.shape[0],1))\n",
    "hufflepuff = np.zeros((X1.shape[0],1))\n",
    "ravenclaw = np.zeros((X1.shape[0],1))\n",
    "slytherin = np.zeros((X1.shape[0],1))\n",
    "\n",
    "female = np.zeros((X1.shape[0],1))\n",
    "male = np.zeros((X1.shape[0],1))\n",
    "\n",
    "print(X1[0])\n",
    "\n",
    "\"\"\"\n",
    "if you want, we can use this to get rid of the Yes/No in the csv and turn them into 1/0:\n",
    "I feel like 1/0 \n",
    "\"\"\"\n",
    "for row in data:\n",
    "    for column in row:\n",
    "        if column == \"Yes\" or \"YES\":\n",
    "            column = 1\n",
    "        elif column == \"No\" or \"NO\":\n",
    "            column = 0\n",
    "\n",
    "for row in range(len(X1)):\n",
    "    if X1[row][0]==\"Gryffindor\":\n",
    "        gryffindor[row]=True\n",
    "    elif X1[row][0]==\"Hufflepuff\":\n",
    "        hufflepuff[row]=True\n",
    "    elif X1[row][0]==\"Ravenclaw\":\n",
    "        ravenclaw[row]=True\n",
    "    elif X1[row][0]==\"Slytherin\":\n",
    "        slytherin[row]=True\n",
    "        \n",
    "    if X1[row][1]==\"Female\":\n",
    "        female[row]=True\n",
    "    elif X1[row][1]==\"Male\":\n",
    "        male[row]=True\n",
    "        \n",
    "    if X1[row][-1]==\"Yes\":\n",
    "        X1[row][-1]=1\n",
    "    else:\n",
    "        X1[row][-1]=0\n",
    "        \n",
    "    if X1[row][-2]==\"Ch\":\n",
    "        X1[row][-2]=1\n",
    "    else:\n",
    "        X1[row][-2]=0\n",
    "        \n",
    "print(X1[0])\n",
    "        \n",
    "X1 = np.hstack((X1,gryffindor,hufflepuff,ravenclaw,slytherin,female,male))\n",
    "X = np.delete(X1,[0,1],1)\n",
    "print(X[0])\n",
    "\n",
    "print(X[0:20,-6:-2])\n",
    "print(X[0:20,-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX=X[0:50634]\n",
    "testX=X[50534:101267]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Steady'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-d282b9f61334>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m#train test split:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m#preprocessing to scale the data and use train_test_split to split the data (70% train and 30% test)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mx_scale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_scale\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Vaneeza Kamil\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mscale\u001b[1;34m(X, axis, with_mean, with_std, copy)\u001b[0m\n\u001b[0;32m    131\u001b[0m     X = check_array(X, accept_sparse='csc', copy=copy, ensure_2d=False,\n\u001b[0;32m    132\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'the scale function'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m                     dtype=FLOAT_DTYPES)\n\u001b[0m\u001b[0;32m    134\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mwith_mean\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Vaneeza Kamil\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    400\u001b[0m                                       force_all_finite)\n\u001b[0;32m    401\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m         \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Steady'"
     ]
    }
   ],
   "source": [
    "\"\"\"this is from the slides for logisitic regression:\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(solver=â€˜lbfgs',multi_class='multinomial')\n",
    "clf.fit(X_train, y_train)\n",
    "yhat_test = clf.predict(X_test)\n",
    "score = clf.score(X_test, y_test) \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "#helpful link for log reg: https://towardsdatascience.com/logistic-regression-a-simplified-approach-using-python-c4bc81a87c31\n",
    "\n",
    "#train test split:\n",
    "#preprocessing to scale the data and use train_test_split to split the data (70% train and 30% test)\n",
    "x_scale = preprocessing.scale(X)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_scale, Y)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "\"\"\"\n",
    "#this trains and predicts\n",
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(X_train,y_train)\n",
    "predictions = logmodel.predict(X_test)\n",
    "\n",
    "#check precision, recall, f1-score using classification report\n",
    "print(classification_report(y_test,predictions))\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"another option found in hw5\"\"\"\n",
    "#log reg with lasso(l1) regularization\n",
    "# Initialize an empty list to store values of training set accuracy.\n",
    "acc_train_logreg = [] \n",
    "# Initialize an empty list to store values of test set accuracy.\n",
    "acc_test_logreg = []\n",
    "# Initialize an empty list to store different values of parameter 'c'.\n",
    "c_logreg = []\n",
    "# Complete the function logreg that accepts 'c' as a parameter, which is used to create logreg model \n",
    "# with different values of C.\n",
    "def logreg_model(c , X_train, Y_train, X_test, Y_test):\n",
    "    # Create an object of logistic regression model using linear_model.\n",
    "    # Pass the value of penalty as 'L1'. By default, it is 'L2'.\n",
    "    # Pass the value of C = c. Note that C is the inverse of lambda. So, small value of C i.e. b/w 0 and 1 \n",
    "    # means stronger regularization and large value means less regularization.\n",
    "    # Also, in sklearn, L1 is only supported with solver = 'saga'. Solver is the type of optimization algorithm like GDA or\n",
    "    # SGDA, which is to be used. So, 'saga' is another algorithm like that. Pass the value of solver as 'saga'\n",
    "\n",
    "    #Create the Logistic Regression model object as described above and save it to logreg\n",
    "    logreg = linear_model.LogisticRegression(C=c,penalty='l1', warm_start=True, solver='saga')\n",
    "    \n",
    "    #Fit the model on the training set\n",
    "    logreg.fit(X_train, Y_train)\n",
    "    \n",
    "    #Find the prediction on training set\n",
    "    Yhat_train = logreg.predict(X_train)\n",
    "    \n",
    "    # Adding training accuracy to acc_train_logreg\n",
    "    acc_train = np.mean(Yhat_train == Y_train)\n",
    "    acc_train_logreg.append(acc_train)\n",
    "    print(\"Accuracy on training data = %f\" % acc_train)\n",
    "    \n",
    "    #Find the prediction on test set\n",
    "    Yhat_test = logreg.predict(X_test)\n",
    "    \n",
    "    # Adding testing accuracy to acc_test_logreg\n",
    "    acc_test = np.mean(Yhat_test == Y_test)\n",
    "    acc_test_logreg.append(acc_test)\n",
    "    print(\"Accuracy on test data = %f\" % acc_test)\n",
    "    \n",
    "    # Appending value of c for graphing purposes\n",
    "    c_logreg.append(c)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "#pick an appropriate value for c and CHANGE the next line:\n",
    "c = 10000\n",
    "logreg_model(c,x_train,y_train,x_test,x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.polynomial.polynomial as poly\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"qudditch_training.csv\")\n",
    "#df = (df[~np.isnull(df).any(axis=1)])\n",
    "df.drop([\"id\",\"player_id\",\"weight\",\"foul_type_id\",\"game_move_id\",\"penalty_id\",\"player_code\",\"move_speciality\",\"snitchnip\",\n",
    "         \"checking\",\"dopplebeater_defence\",\"hawkshead_attacking_formation\",\"no_hands_tackle\",\"power_play\",\"spiral_dive\",\n",
    "         \"starfish_and_stick\",\"twirl\",\"wronski_feint\",\"zig-zag\",\"bludger_backbeat\",\"chelmondiston_charge\",\n",
    "         \"dionysus_dive\",\"double_eight_loop\",\"finbourgh_flick\",\"parkins_pincer\",\"plumpton_pass\",\"porskoff_ploy\",\n",
    "         \"transylvanian_tackle\",\"woollongong_shimmy\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['house', 'gender', 'age', 'game_duration', 'num_game_moves',\n",
      "       'num_game_losses', 'num_practice_sessions', 'num_games_satout',\n",
      "       'num_games_injured', 'num_games_notpartof', 'player_type',\n",
      "       'num_games_won', 'stooging', 'body_blow', 'sloth_grip_roll',\n",
      "       'reverse_pass', 'change', 'snitch_caught', 'quidditch_league_player'],\n",
      "      dtype='object')\n",
      "(101267, 19)\n",
      "(101268, 1)\n",
      "['Gryffindor' 'Female' 11.0 1.0 41.0 0.0 1.0 0.0 0.0 0.0 'Beater' 1.0\n",
      " 'None' 'No' 'No' 'No' 'No' 'No' 'NO']\n",
      "[11.0 1.0 41.0 0.0 1.0 0.0 0.0 0.0 1.0 0 0 'No' 'No' 'No' False 'NO' 1.0\n",
      " 0.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0]\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "data = df.values\n",
    "X1 = data[0:101267]\n",
    "\n",
    "Y = data[:,-1]\n",
    "print(X1.shape)\n",
    "\n",
    "Y = Y=='YES'\n",
    "Y = Y.reshape((Y.shape[0],1))\n",
    "print(Y.shape)\n",
    "\n",
    "gryffindor = np.zeros((X1.shape[0],1))\n",
    "hufflepuff = np.zeros((X1.shape[0],1))\n",
    "ravenclaw = np.zeros((X1.shape[0],1))\n",
    "slytherin = np.zeros((X1.shape[0],1))\n",
    "\n",
    "female = np.zeros((X1.shape[0],1))\n",
    "male = np.zeros((X1.shape[0],1))\n",
    "\n",
    "beater = np.zeros((X1.shape[0],1))\n",
    "chaser = np.zeros((X1.shape[0],1))\n",
    "seeker = np.zeros((X1.shape[0],1))\n",
    "\n",
    "print(X1[0])\n",
    "\n",
    "for row in range(len(X1)):\n",
    "    if X1[row][0]==\"Gryffindor\":\n",
    "        gryffindor[row]=1\n",
    "    elif X1[row][0]==\"Hufflepuff\":\n",
    "        hufflepuff[row]=1\n",
    "    elif X1[row][0]==\"Ravenclaw\":\n",
    "        ravenclaw[row]=1\n",
    "    elif X1[row][0]==\"Slytherin\":\n",
    "        slytherin[row]=1\n",
    "        \n",
    "    if X1[row][1]==\"Female\":\n",
    "        female[row]=1\n",
    "    elif X1[row][1]==\"Male\":\n",
    "        male[row]=1\n",
    "        \n",
    "#    if X1[row][7]==\"?\":\n",
    "#        X1[row][7]=0;\n",
    "#    else:\n",
    "#        X1[row][7]=float(X1[row][7])\n",
    "\n",
    "    if X1[row][10]==\"Beater\":\n",
    "        beater[row]=1\n",
    "    elif X1[row][10]==\"Chaser\":\n",
    "        chaser[row]=1\n",
    "    elif X1[row][10]==\"Seeker\":\n",
    "        seeker[row]=1\n",
    "        \n",
    "    if X1[row][12]==\"Normal\":\n",
    "        X1[row][12]=1\n",
    "    elif X1[row][12]==\">7\":\n",
    "        X1[row][12]=2\n",
    "    elif X1[row][12]==\">8\":\n",
    "        X1[row][12]=3\n",
    "    elif X1[row][12]==\"None\":\n",
    "        X1[row][12]=0\n",
    "    \n",
    "    if X1[row][13]==\"No\":\n",
    "        X1[row][13]=0\n",
    "    elif X1[row][13]==\"Down\":\n",
    "        X1[row][13]=1\n",
    "    elif X1[row][13]==\"Steady\":\n",
    "        X1[row][13]=2\n",
    "    elif X1[row][13]==\"Up\":\n",
    "        X1[row][13]=3\n",
    "        \n",
    "X1[:,-1] = X1[:,-1]==\"Yes\"\n",
    "X1[:,-2] = X1[:,-2]==\"Ch\"\n",
    "\n",
    "X1 = np.hstack((X1,gryffindor,hufflepuff,ravenclaw,slytherin,female,male,beater,chaser,seeker))\n",
    "#X1: ['house', 'gender', 'age', 'game_duration', 'num_game_moves',\n",
    "#       'num_game_losses', 'num_practice_sessions', 'num_games_satout',\n",
    "#       'num_games_injured', 'num_games_notpartof', 'player_type',\n",
    "#       'num_games_won', 'stooging', 'body_blow', 'sloth_grip_roll',\n",
    "#       'reverse_pass', 'change', 'snitch_caught', 'quidditch_league_player',\n",
    "#       'gryffindor','hufflepuff','ravenclaw','slytherin','female','male',\n",
    "#       'beater','chaser','seeker']\n",
    "X = np.delete(X1,[0,1,10],1)\n",
    "print(X[0])\n",
    "\n",
    "#print(X[0:20,-6:-2])\n",
    "#print(X[0:20,-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_scale = preprocessing.scale(X)\n",
    "X = X_scale.fit_transform(digits.data)\n",
    "\n",
    "trainX,testX,trainY,testY=train_test_split(X,Y,test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Variations:\n",
    "# Regularization (use L1 and L2)\n",
    "# Polynomial Features\n",
    "# c values\n",
    "\n",
    "#this is from the slides for logisitic regression\n",
    "clf = LogisticRegression(solver='lbfgs',multi_class='multinomial')\n",
    "clf.fit(trainX, trainY)\n",
    "yhat_test = clf.predict(testX)\n",
    "score = clf.score(testX, testY)\n",
    "\n",
    "#helpful link for log reg: https://towardsdatascience.com/logistic-regression-a-simplified-approach-using-python-c4bc81a87c31\\n\",\n",
    "\n",
    "#train test split:\\n\",\n",
    "#preprocessing to scale the data and use train_test_split to split the data (70% train and 30% test)\\n\",\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_scale, Y)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "#this trains and predicts\\n\",\n",
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(X_train,y_train)\n",
    "predictions = logmodel.predict(X_test)\n",
    "\n",
    "#check precision, recall, f1-score using classification report\\n\",\n",
    "print(classification_report(y_test,predictions))\n",
    "\n",
    "#another option found in hw5\n",
    "#log reg with lasso(l1) regularization\n",
    "# Initialize an empty list to store values of training set accuracy.\n",
    "acc_train_logreg = []\n",
    "# Initialize an empty list to store values of test set accuracy.\n",
    "acc_test_logreg = []\n",
    "# Initialize an empty list to store different values of parameter 'c'.\n",
    "c_logreg = []\n",
    "# Complete the function logreg that accepts 'c' as a parameter, which is used to create logreg model \n",
    "# with different values of C.\n",
    "def logreg_model(c , X_train, Y_train, X_test, Y_test,reg=None):\n",
    "    # Create an object of logistic regression model using linear_model.\n",
    "    # Pass the value of penalty as 'L1'. By default, it is 'L2'.\n",
    "    # Pass the value of C = c. Note that C is the inverse of lambda. So, small value of C i.e. b/w 0 and 1 \\n\",\n",
    "    # means stronger regularization and large value means less regularization.\\n\",\n",
    "    # Also, in sklearn, L1 is only supported with solver = 'saga'. Solver is the type of optimization algorithm like GDA or\\n\",\n",
    "    # SGDA, which is to be used. So, 'saga' is another algorithm like that. Pass the value of solver as 'saga\n",
    "    #Create the Logistic Regression model object as described above and save it to logreg\\n\",\n",
    "    \n",
    "    if reg==\"LASSO\" or reg==\"Lasso\" or reg==\"lasso\" or reg==None:\n",
    "        logreg = linear_model.LogisticRegression(C=c,penalty='l2', warm_start=True, solver='saga')\n",
    "    elif reg==\"Ridge\" or reg==\"ridge\":\n",
    "        logreg = linear_model.LogisticRegression(C=c,penalty='l1', warm_start=True, solver='saga')\n",
    "    \n",
    "    #Fit the model on the training set\\n\",\n",
    "    logreg.fit(X_train, Y_train)\n",
    "    \n",
    "    #Find the prediction on training set\\n\",\n",
    "    Yhat_train = logreg.predict(X_train)\n",
    "    \n",
    "    # Adding training accuracy to acc_train_logreg\\n\",\n",
    "    acc_train = np.mean(Yhat_train == Y_train)\n",
    "    acc_train_logreg.append(acc_train)\n",
    "    print(\\\"Accuracy on training data = %f\\\" % acc_train)\n",
    "    \n",
    "    #Find the prediction on test set\\n\",\n",
    "    Yhat_test = logreg.predict(X_test)\n",
    "    \n",
    "    # Adding testing accuracy to acc_test_logreg\\n\",\n",
    "    acc_test = np.mean(Yhat_test == Y_test)\n",
    "    acc_test_logreg.append(acc_test)\n",
    "    print(\\\"Accuracy on test data = %f\\\" % acc_test)\n",
    "    # Appending value of c for graphing purposes\\n\",\n",
    "    c_logreg.append(c)\n",
    "    \n",
    "    \n",
    "#pick an appropriate value for c and CHANGE the next line:\\n\",\n",
    "c = 10000\n",
    "logreg_model(c,x_train,y_train,x_test,x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "\n",
    "def f_deriv(z):\n",
    "    return f(z) * (1 - f(z))\n",
    "\n",
    "def f2(z):\n",
    "    if z>0:\n",
    "        return z\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def f2_deriv(z):\n",
    "    if z>0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def f3(z):\n",
    "    return (np.exp(z)-np.exp(-z))/(np.exp(z)+np.exp(-z))\n",
    "\n",
    "def f3_deriv(z):\n",
    "    return 1-(f3(z))^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setup_and_init_weights(nn_structure):\n",
    "    W = {} #creating a dictionary i.e. a set of key: value pairs\n",
    "    b = {}\n",
    "    for l in range(1, len(nn_structure)):\n",
    "        W[l] = r.random_sample((nn_structure[l], nn_structure[l-1])) #Return “continuous uniform” random floats in the half-open interval [0.0, 1.0). \n",
    "        b[l] = r.random_sample((nn_structure[l],))\n",
    "    return W, b\n",
    "\n",
    "def init_tri_values(nn_structure):\n",
    "    tri_W = {}\n",
    "    tri_b = {}\n",
    "    for l in range(1, len(nn_structure)):\n",
    "        tri_W[l] = np.zeros((nn_structure[l], nn_structure[l-1]))\n",
    "        tri_b[l] = np.zeros((nn_structure[l],))\n",
    "    return tri_W, tri_b\n",
    "\n",
    "def feed_forward(x, W, b, act_func=1):\n",
    "    a = {1: x}\n",
    "    z = {}\n",
    "    for l in range(1, len(W) + 1):\n",
    "        node_in = a[l]\n",
    "        z[l+1] = W[l].dot(node_in) + b[l]\n",
    "        if act_func==1:\n",
    "            a[l+1] = f(z[l+1])\n",
    "        elif act_func == 2:\n",
    "            a[l+1] = f2(z[l+1])\n",
    "        elif act_func == 3:\n",
    "            a[l+1] = f3(z[l+1])\n",
    "        \n",
    "    return a, z\n",
    "\n",
    "def calculate_out_layer_delta(y, a_out, z_out, W, lmda, act_func=1):\n",
    "    if act_func==1:\n",
    "        return -(y-a_out) * f_deriv(z_out) + (lmda/2) * W\n",
    "    elif act_func==2:\n",
    "        return -(y-a_out) * f2_deriv(z_out) + (lmda/2) * W\n",
    "    elif act_func==3:\n",
    "        return -(y-a_out) * f3_deriv(z_out) + (lmda/2) * W\n",
    "\n",
    "\n",
    "def calculate_hidden_delta(delta_plus_1, w_l, z_l, act_func=1):\n",
    "    if act_func==1:\n",
    "        return np.dot(np.transpose(w_l), delta_plus_1) * f_deriv(z_l)\n",
    "    elif act_func==2:\n",
    "        return np.dot(np.transpose(w_l), delta_plus_1) * f2_deriv(z_l)\n",
    "    elif act_func==3:\n",
    "        return np.dot(np.transpose(w_l), delta_plus_1) * f3_deriv(z_l)\n",
    "\n",
    "def train_nn(nn_structure, X, y, iter_num=3000, alpha=0.25, act_func=1):\n",
    "    W, b = setup_and_init_weights(nn_structure)\n",
    "    cnt = 0\n",
    "    N = len(y)\n",
    "    avg_cost_func = []\n",
    "    print('Starting gradient descent for {} iterations'.format(iter_num))\n",
    "    while cnt < iter_num:\n",
    "        if cnt%1000 == 0:\n",
    "            print('Iteration {} of {}'.format(cnt, iter_num))\n",
    "        tri_W, tri_b = init_tri_values(nn_structure)\n",
    "        avg_cost = 0\n",
    "        for i in range(N):\n",
    "            delta = {}\n",
    "            a, z = feed_forward(X[i, :], W, b,act_func)\n",
    "            for l in range(len(nn_structure), 0, -1):\n",
    "                if l == len(nn_structure):\n",
    "                    delta[l] = calculate_out_layer_delta(y[i,:], a[l], z[l], W[l], lmbda.act_func)\n",
    "                    avg_cost += np.linalg.norm((y[i,:]-a[l]))\n",
    "                else:\n",
    "                    if l > 1:\n",
    "                        delta[l] = calculate_hidden_delta(delta[l+1], W[l], z[l],act_func)\n",
    "                    tri_W[l] += np.dot(delta[l+1][:,np.newaxis], np.transpose(a[l][:,np.newaxis]))\n",
    "                    tri_b[l] += delta[l+1]\n",
    "        for l in range(len(nn_structure) - 1, 0, -1):\n",
    "            W[l] += -alpha * (1.0/N * tri_W[l])\n",
    "            b[l] += -alpha * (1.0/N * tri_b[l])\n",
    "        avg_cost = 1.0/N * avg_cost\n",
    "        avg_cost_func.append(avg_cost)\n",
    "        cnt += 1\n",
    "    return W, b, avg_cost_func\n",
    "\n",
    "\n",
    "def predict_y(W, b, X, n_layers):\n",
    "    N = X.shape[0]\n",
    "    y = np.zeros((N,))\n",
    "    for i in range(N):\n",
    "        a, z = feed_forward(X[i, :], W, b)\n",
    "        y[i] = np.argmax(a[n_layers])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn_structure1 = [27, 10, 1]\n",
    "nn_structure2 = [27, 20, 1]\n",
    "nn_structure3 = [27, 5, 1]\n",
    "\n",
    "nn_structure4 = [27, 10, 10, 1]\n",
    "nn_structure5 = [27, 10, 10, 10, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_1, b_1, avg_cost_func_1 = train_nn(nn_structure1, X_train, y_v_train, 3000,act_func=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_2, b_2, avg_cost_func_2 = train_nn(nn_structure1, X_train, y_v_train, 3000,act_func=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_3, b_3, avg_cost_func_3 = train_nn(nn_structure1, X_train, y_v_train, 3000,act_func=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_4, b_4, avg_cost_func_4 = train_nn(nn_structure2, X_train, y_v_train, 3000,act_func=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_5, b_5, avg_cost_func_5 = train_nn(nn_structure3, X_train, y_v_train, 3000,act_func=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_6, b_6, avg_cost_func_6 = train_nn(nn_structure4, X_train, y_v_train, 3000,act_func=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_7, b_7, avg_cost_func_7 = train_nn(nn_structure5, X_train, y_v_train, 3000,act_func=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
